{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "ecda20238df2ed8e9d74a8333869d6ab36a80806eec0e5f6f1311a96726d7d59"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialInfluence:\n",
    "    def __init__(self, n_nodes, n_steps):\n",
    "        self.cat = 4\n",
    "        self.user_cat = np.random.randint(1,self.cat+1,n_nodes)\n",
    "        self.edges = np.random.binomial(n=1,p=0.6,size=[n_nodes,n_nodes])\n",
    "        self.act = np.ndarray((n_nodes,n_nodes), dtype=float)\n",
    "        for i in range(n_nodes):\n",
    "            for j in range(n_nodes):\n",
    "                if i == j:\n",
    "                    #Diagonal represents the click probability of the user\n",
    "                    self.act[i][j] = 1#0.5 + np.random.rand(1)[0]*0.5\n",
    "                else:\n",
    "                    #print(i,j,\"not diag\")\n",
    "                    #print(act[i][j])\n",
    "                    if (self.user_cat[i] != self.user_cat[j] or self.edges[i][j]!=1):\n",
    "                        #print(\"existing edge\",act[i][j])\n",
    "                        self.act[i][j] = 0\n",
    "                        #print(act[i][j])\n",
    "                    else:\n",
    "                        self.act[i][j] = 0.2 + np.random.rand(1)[0]*0.5\n",
    "        self.init_prob_matrix = self.act\n",
    "        print(self.act)\n",
    "        #np.random.uniform(0.0,0.1,(n_nodes,n_nodes))\n",
    "        self.n_steps_max = n_steps\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "    def simulate_episode(self, activated_nodes):\n",
    "        self.prob_matrix = self.init_prob_matrix.copy()\n",
    "        #n_nodes = prob_matrix.shape[0]\n",
    "        self.initial_active_nodes = np.zeros(self.n_nodes)\n",
    "        #for node in activated_nodes:\n",
    "        self.initial_active_nodes[activated_nodes] = 1\n",
    "        self.history = np.array([self.initial_active_nodes])\n",
    "        self.active_nodes = self.initial_active_nodes\n",
    "        self.newly_active_nodes = self.active_nodes\n",
    "        self.t=0\n",
    "        while(self.t<self.n_steps_max and np.sum(self.newly_active_nodes)>0):\n",
    "            self.p = (self.prob_matrix.T* self.active_nodes).T\n",
    "            self.activated_edges = self.p>np.random.rand(self.p.shape[0], self.p.shape[1])\n",
    "            self.prob_matrix = self.prob_matrix*((self.p!=0)==self.activated_edges)\n",
    "            self.newly_active_nodes = (np.sum(self.activated_edges,axis=0)>0) * (1 - self.active_nodes)\n",
    "            self.history = np.concatenate((self.history, [self.newly_active_nodes]),axis = 0)\n",
    "            self.t+=1\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMabEnviroment():\n",
    "    def __init__(self, n_arms, dim):\n",
    "        self.theta = np.random.dirichlet(np.ones(dim), size = 1)\n",
    "        #print(self.theta)\n",
    "        self.arms_features = np.random.binomial(1, 0.5, size=(n_arms,dim))\n",
    "        #print(self.arms_features)\n",
    "        self.p = np.zeros(n_arms)\n",
    "        for i in range(0,n_arms):\n",
    "            self.p[i] = np.dot(self.theta, self.arms_features[i])\n",
    "\n",
    "    def round(self, pulled_arm):\n",
    "        self.history = episode.simulate_episode(pulled_arm)\n",
    "        return np.sum(self.history)\n",
    "        #return 1 if np.random.random() < self.p[pulled_arm] else 0\n",
    "\n",
    "    # def opt(self):\n",
    "    #     return np.max(self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinUcbLearner():\n",
    "    def  __init__(self, arms_features):\n",
    "        self.arms =arms_features\n",
    "        self.dim = arms_features.shape[1]\n",
    "        self.collected_rewards = []\n",
    "        self.pulled_arms = []\n",
    "        self.c = 2.0\n",
    "        self.M = np.identity(self.dim)\n",
    "        self.b = np.atleast_2d(np.zeros(self.dim)).T\n",
    "        self.theta = np.dot(np.linalg.inv(self.M), self.b)\n",
    "\n",
    "    def compute_ucbs(self):\n",
    "        self.theta = np.dot(np.linalg.inv(self.M), self.b)\n",
    "        ucbs = []\n",
    "        for arm in self.arms:\n",
    "            arm = np.atleast_2d(arm).T\n",
    "            ucb = np.dot(self.theta.T, arm) + self.c * np.sqrt(np.dot(arm.T, np.dot(np.linalg.inv(self.M), arm)))#need to understand\n",
    "            ucbs.append(ucb[0][0])\n",
    "        return ucbs\n",
    "\n",
    "    def pull_arm(self):\n",
    "        ucbs = self.compute_ucbs()\n",
    "        #print(ucbs)\n",
    "        return np.argmax(ucbs)\n",
    "\n",
    "    def update_estimation(self, arm_idx, reward):\n",
    "        arm = np.atleast_2d(self.arms[arm_idx]).T\n",
    "        self.M += np.dot(arm, arm.T)\n",
    "        self.b += reward*arm\n",
    "\n",
    "    def update(self, arm_idx, reward):\n",
    "        self.pulled_arms.append(arm_idx)\n",
    "        self.collected_rewards.append(reward)\n",
    "        self.update_estimation(arm_idx, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = 15\n",
    "T = 100\n",
    "n_experiments = 10\n",
    "lin_ucb_rewards_per_experiment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.         0.56412465 0.         0.         0.         0.\n  0.         0.         0.         0.34641984 0.         0.\n  0.         0.         0.        ]\n [0.67653922 1.         0.40203244 0.         0.         0.\n  0.         0.         0.         0.50759108 0.         0.\n  0.         0.         0.        ]\n [0.         0.24362912 1.         0.63273925 0.         0.\n  0.         0.         0.         0.46303612 0.         0.\n  0.         0.         0.        ]\n [0.47445594 0.2043475  0.56364841 1.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.        ]\n [0.         0.         0.         0.         1.         0.\n  0.22171058 0.         0.         0.         0.55250882 0.\n  0.44256056 0.         0.        ]\n [0.         0.         0.         0.         0.         1.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.61942115]\n [0.         0.         0.         0.         0.34145729 0.\n  1.         0.         0.28579058 0.         0.68278068 0.\n  0.32815988 0.47280081 0.        ]\n [0.         0.         0.         0.         0.         0.69878336\n  0.         1.         0.         0.         0.         0.\n  0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.331642   0.         1.         0.         0.         0.\n  0.31526851 0.39908612 0.        ]\n [0.         0.58493106 0.32255403 0.         0.         0.\n  0.         0.         0.         1.         0.         0.\n  0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         1.         0.\n  0.3051868  0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         1.\n  0.         0.         0.        ]\n [0.         0.         0.         0.         0.46906312 0.\n  0.         0.         0.43678116 0.         0.         0.\n  1.         0.         0.        ]\n [0.         0.         0.         0.         0.2836567  0.\n  0.65248694 0.         0.         0.         0.3286404  0.\n  0.41009813 1.         0.        ]\n [0.         0.         0.         0.         0.         0.3671111\n  0.         0.31472439 0.         0.         0.         0.\n  0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "env = LinearMabEnviroment(n_arms=n_arms, dim=10)\n",
    "episode = SocialInfluence(n_arms,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0,n_experiments):\n",
    "    lin_ucb_learner = LinUcbLearner(arms_features=env.arms_features)\n",
    "    for t in range(0,T):\n",
    "        pulled_arm = lin_ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        lin_ucb_learner.update(pulled_arm, reward)\n",
    "    lin_ucb_rewards_per_experiment.append(lin_ucb_learner.collected_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}